{% include mathjax.html %}

# 2A - ModÃ¨le Probabiliste
[*Retour Ã  l'accueil*](./../README.md)

## Menu

- [2A - ModÃ¨le Probabiliste](#2a---modÃ¨le-probabiliste)
  - [Menu](#menu)
  - [SystÃ¨me complet d'Ã©vÃ©nements](#systÃ¨me-complet-dÃ©vÃ©nements)
  - [ProbabilitÃ©](#probabilitÃ©)
  - [IndÃ©pendance](#indÃ©pendance)
  - [ProbabilitÃ© Conditionelle](#probabilitÃ©-conditionelle)
  - [Variables alÃ©atoires discrÃ¨tes](#variables-alÃ©atoires-discrÃ¨tes)
  - [Lois de probabilitÃ© DiscrÃ¨tes](#lois-de-probabilitÃ©-discrÃ¨tes)
      - [EspÃ©rance](#espÃ©rance)
      - [Variance](#variance)
      - [Fonction de rÃ©partition](#fonction-de-rÃ©partition)
      - [DiffÃ©rentes lois de probabilitÃ© discrÃ¨tes](#diffÃ©rentes-lois-de-probabilitÃ©-discrÃ¨tes)
  - [Lois de probabilitÃ© continues](#lois-de-probabilitÃ©-continues)
      - [Fonction densitÃ© de probabilitÃ©](#fonction-densitÃ©-de-probabilitÃ©)
      - [EspÃ©rance, Variance](#espÃ©rance-variance)
      - [DiffÃ©rentes lois de probabilitÃ© continues](#diffÃ©rentes-lois-de-probabilitÃ©-continues)
- [Formules](#formules)


___
> $$Î©$$ **Espace fondamental :** ensemble des rÃ©sultats possibles d'une expÃ©rience alÃ©atoire (totalitÃ© d'un diagramme de Venn).
> $$(Î©, P(Î©))$$ **Espace Probabilisable :** ensemble des Ã©vÃ©nements de l'univers $$Î©$$.
> $$(Î©, P(Î©), p)$$ **Espace probabilisÃ© :** probabilitÃ© $$p$$ sur l'univers $$Î©$$.

> **ExpÃ©rience alÃ©atoire :** expÃ©rience dont on ne connait le rÃ©sultat qu'aprÃ¨s l'avoir exÃ©cutÃ©e, mais dont on connait toutes les issues.
> **Ã‰vÃ©nement :** sous-ensemble de l'univers d'une expÃ©rience alÃ©atoire.




___
## SystÃ¨me complet d'Ã©vÃ©nements
Un SCE est formÃ© de toutes les parties de $$Î©$$.
ğŸ“Œ $$âˆªE_{i}=Î©$$  
les parties de $$Î©$$ ne sont prises qu'une fois : $$Eâ‚âˆ©Eâ‚‚=âˆ…$$  
âœğŸ» $$A$$ et $$\bar{A}$$ forment un SCE. C'est pourquoi ğŸ“Œ$$P(B)=P(Aâˆ©B)+P(\bar{A}âˆ©B)$$.







___
## ProbabilitÃ©
Une **probabilitÃ©** se dÃ©finit par l'**application** :  
$$ğŸ“ŒP: 
\begin{cases}
Î© â†’ [0,1] \\
A â†¦ P(A)
\end{cases}$$ 

âœğŸ» Une **application** $$Aâ†’B$$ est une opÃ©ration qui fait correspondre Ã  tout Ã©lÃ©ment x de A **un seul** Ã©lÃ©ment y de B.

> Une probabilitÃ© vÃ©rifie :  
> $$P(A)âŠ‚[0,1]$$  
> $$P(Î©)=1$$  
> ğŸ“Œ$$P(A)âˆªP(B) = P(A)+P(B)$$ *(si compatibles :)* $$-P(A)âˆ©P(B)$$

âœğŸ» PropriÃ©tÃ©s :
- AdditivitÃ© : $$P(Aâˆª\bar{A}) = P(A)+P(\bar{A})$$
- propriÃ©tÃ© de la rÃ©union : $$Aâˆª\bar{A}=Î©$$
- propriÃ©tÃ© de l'intersection : $$Aâˆ©\bar{A} = âˆ…$$

âœğŸ» Soit les Ã©vÃ©nements A, B et C :
- au moins un = $$AâˆªBâˆªC$$
- tous = $$Aâˆ©Bâˆ©C$$
- au plus 2 = tout sauf tous = $$(\overline{Aâˆ©Bâˆ©C})$$

> #### Formule des probabilitÃ©s totales
> Si Bâ‚, Bâ‚‚, Bâ‚ƒ forment une partition de Î©, alors  
> ğŸ“Œ$$P(A)=P(Aâˆ©Bâ‚)+P(Aâˆ©Bâ‚‚)+P(Aâˆ©Bâ‚ƒ)$$

> #### Ã‰quiprobabilitÃ©
> ğŸ“Œ$$P(A)=\frac{card(A)}{card(Î©)}$$  
> avec $$card(E)$$ : taille de l'ensemble E






___
## IndÃ©pendance
> #### ThÃ©orÃ¨me de l'IndÃ©pendance
> ğŸ“ŒA et B indÃ©pendants ssi $$P(Aâˆ©B)=P(A)P(B)$$
> 
> âœğŸ» Dans ce cas,
> $$P_{A}(B)=P(B)$$  
> $$P_{A}$$ et $$B$$ indÃ©pendants. 






___
## ProbabilitÃ© Conditionelle
> La probabilitÃ© de B dÃ©pendant de A est notÃ©e $$P_{A}(B)$$.  
> ğŸ“Œ$$P_{A}(B)=\frac{P(Aâˆ©B)}{P(A)}$$

> #### Formule des probabilitÃ©s composÃ©es
> ğŸ“Œ$$P(Aâˆ©B)=P(A)P_{A}(B)$$





___
## Variables alÃ©atoires discrÃ¨tes
Pour toute VA $$X$$ :
$$ğŸ“Œx: 
\begin{cases}
Î© â†’ â„ \\
Ï‰áµ¢ â†¦ x(Ï‰áµ¢)=xáµ¢
\end{cases}$$ 




___
## Lois de probabilitÃ© DiscrÃ¨tes

> **Loi de probabilitÃ© de X :** ProbabilitÃ© que x prenne chacune des valeurs de X(Î©).
>
|xáµ¢     |0  |1  |2  |
|--     |-- |-- |-- |
|P(X=xáµ¢)|1/8|2/8|5/8|

âœğŸ» Les Ã©vÃ©nements X=xáµ¢ forment un [SystÃ¨me complet d'Ã©vÃ©nements](#systÃ¨me-complet-dÃ©vÃ©nements). C'est pourquoi $$\sum_{i}P(X=xáµ¢)=1$$.

#### EspÃ©rance
Somme des xáµ¢ pondÃ©rÃ©s par leur probabilitÃ©. 
ğŸ“Œ $$E(X) = Î£(xáµ¢) P(X=xáµ¢)$$  

$$E(X+Y)=E(X)+E(Y)$$  
$$E(kX)=kE(X)$$  
$$E(X+a)=E(X)+a$$

#### Variance 
> Somme des carrÃ©s des Ã©carts Ã  la moyenne :   
> $$= \sum(xáµ¢-E(X))Â² P(X=xáµ¢)$$  
> $$= \sum(xÂ² P(X=xáµ¢))$$  
> $$= E(XÂ²)-E(X)Â²$$  
> ğŸ“Œ$$V(X) = E[(X-E(X))Â²]$$

> **Ã‰cart-type :** ğŸ“Œ$$Ïƒ=\sqrt{V(X)}$$

$$V(X+Y)=V(X)+V(Y)$$  
$$V(kX)=kÂ²V(X)$$  
$$V(X+a)=V(X)$$

#### Fonction de rÃ©partition
$$ğŸ“Œx: 
\begin{cases}
â„ â†’ â„ \\
t â†¦ F(t)=P(Xâ‰¤t)
\end{cases}$$ 
> âœğŸ» Sa reprÃ©sentation est un escalier toujours montant car on inclut toujours les probabilitÃ©s infÃ©rieures.
> $$FâŠ‚â„$$
> $$Fâ†—$$
> $$0â‰¤F(t)â‰¤1$$
> $$\lim_{tâ†’0}F(t)=0$$
> $$\lim_{tâ†’âˆ}F(t)=1$$

> $$P(aâ‰¤Xâ‰¤b)=P(Xâ‰¤b)-P(Xâ‰¤a)=F(b)-F(a)$$
> P(X>a)=1-P(Xâ‰¤a)=1-F(a)

#### DiffÃ©rentes lois de probabilitÃ© discrÃ¨tes

|Notation|Nom      |E(X)  |V(X)       |P(X=k)|
|--      |--       |--    |--         |--|
B(p\)     |Bernoulli|$$p$$ |$$p(1-p)$$ |$$kn$$
B(n;p)   |Binomiale|$$np$$|$$np(1-p)$$|$$\binom{n}{k} páµ(1-p)â¿â»áµ$$
P(Î»)     |Poisson  |$$Î»$$ |$$Î»$$      |$$\frac{e^{-Î»}Î»^{k}}{k!}$$

- **Loi de Bernoulli :** pour X ne prenant que 2 valeurs.  
  
|X=xáµ¢|0|1|
|--|--|--|
|P(X=xáµ¢)|1-p|p|

- **Loi binomiale :** Un ensemble de probabilitÃ©s suit la loi binomiale **ssi** il forme un **schÃ©ma de Bernoulli** (EBRII).  

âœğŸ» Une loi binomiale s'applique par exemple Ã  un tirage avec remise. 

> Coefficient bionomial : ğŸ“Œ$$\binom{n}{k}=\frac{n!}{k!(n-k)!}$$ 
> - $$\binom{n}{k} = \binom{n}{n-k}$$, 
> - $$\binom{n}{k} + \binom{n}{k+1} = \binom{n+1}{k+1}$$ - *Formule de Pascal*,
> - $$\binom{n}{0} = 1$$,    
> - $$\binom{n}{1} = n$$,    
> - $$\binom{n}{n} = 1$$,    
> - $$\binom{0}{0} = 1$$.    

- **Loi de Poisson :** s'applique aux Ã©vÃ©nements rares.






___
## Lois de probabilitÃ© continues

#### Fonction densitÃ© de probabilitÃ©
On suppose que $$F'(t)=f(t)$$.

âœğŸ» F(t) est la densitÃ© de la loi *continue* de X.

$$f(t)â‰¥0$$  
$$\begin{align}
P(aâ‰¤Xâ‰¤b) &= F(b)-F(a) \\
         &= \int_{a}^{b} f(x) \,dx
\end{align}$$  
$$\begin{align}
P(Xâ‰¤b) &= \int_{-âˆ}^{b}f(x) \,dx \\
       &= \lim_{aâ†’+âˆ} \int_{a}^{b}f(x) \,dx \\
       &= F(b)-\lim_{aâ†’-âˆ}F(a)
\end{align}$$  

#### EspÃ©rance, Variance
$$E(X)=\int_{-âˆ}^{+âˆ}xf(x) \,dx$$  
$$V(X)=E(XÂ²)-E(X)Â²$$ avec $$E(XÂ²)=\int_{-âˆ}^{+âˆ}xÂ²f(x) \,dx$$

#### DiffÃ©rentes lois de probabilitÃ© continues
Notation|Nom            | E(X)              | V(X)                  | FDP f(x)         | f(x)âŠ‚      | P(câ‰¤Xâ‰¤d)
--      |--             |--                 |--                     |--                |--          |--   
U(a;b)  | Uniforme      | $$\frac{a+b}{2}$$ | $$\frac{(b-a)Â²}{12}$$ | $$\frac{1}{b-a}$$| $$[a;b]$$  | $$\frac{d-c}{b-a}$$
E(Î»)    | Exponentielle | $$\frac{1}{Î»}$$   | $$\frac{1}{Î»Â²}$$      | $$Î»e^{-Î»x}$$     | $$[a;+âˆ[$$ | $$e^{-Î»c}-e^{-Î»d}$$
N(m;ÏƒÂ²) | Normale       | $$m$$             | $$ÏƒÂ²$$                | $$\frac{e^{-0,5(\frac{x-n}{Ïƒ})Â²}}{Ïƒ\sqrt{2\pi}}$$|$$\R$$|$$\int_{a}^{b}f(x) \,dx$$
N(0;1)|Normale CentrÃ©e RÃ©duite|$$0$$|$$1$$|$$\frac{e^{xÂ²/2}}{\sqrt{2\pi}}$$|$$\R$$|$$\int_{a}^{b}f(x) \,dx$$

- **Loi normale centrÃ©e rÃ©duite :**   
Comme la FDP est paire (symÃ©trique) : $$P(Tâ‰¤-u) = P(Tâ‰¥u) = 1-P(Tâ‰¤u)$$





# Formules

IncompatibilitÃ© | $$Aâˆ©B=âˆ…$$  

ProbabilitÃ© | $$Îµ(Î©) â†’ [0,1]$$ | $$A â†’ P(A)$$  

ProbabilitÃ©s totales | $$P(A)=P(Aâˆ©Bâ‚)+P(Aâˆ©Bâ‚‚)+P(Aâˆ©Bâ‚ƒ)$$  

Ã‰quiprobabilitÃ© | $$P(A)=\frac{card(A)}{card(Î©)}$$  

Union | $$P(Aâˆ©B)=P(A)P(B)-P(AâˆªB)$$  

IndÃ©pendance | $$P(Aâˆ©B)=P(A)P(B)$$  

ProbabilitÃ©s composÃ©es | $$P(Aâˆ©B)=P(A)P_{A}(B)$$  

Variable AlÃ©atoire | $$x: Î© â‡’ â„$$ | $$Ï‰áµ¢ â‡’ x(Ï‰áµ¢)=xáµ¢$$  

EspÃ©rance | $$Î£(xáµ¢) P(X=xáµ¢)$$  

Variance | $$E[(X-E(X))Â²]$$  
