{% include mathjax.html %}

# 2A - ModÃ¨le Probabiliste
[*Retour Ã  l'accueil*](./../README.md)

## Menu

- [2A - ModÃ¨le Probabiliste](#2a---modÃ¨le-probabiliste)
  - [Menu](#menu)
  - [SystÃ¨me complet d'Ã©vÃ©nements](#systÃ¨me-complet-dÃ©vÃ©nements)
  - [ProbabilitÃ©](#probabilitÃ©)
  - [IndÃ©pendance](#indÃ©pendance)
  - [ProbabilitÃ© Conditionelle](#probabilitÃ©-conditionelle)
  - [Variables alÃ©atoires](#variables-alÃ©atoires)
    - [Fonction de rÃ©partition](#fonction-de-rÃ©partition)
  - [Variables alÃ©atoires discrÃ¨tes](#variables-alÃ©atoires-discrÃ¨tes)
  - [Variables alÃ©atoires continues](#variables-alÃ©atoires-continues)
  - [Lois de probabilitÃ© DiscrÃ¨tes](#lois-de-probabilitÃ©-discrÃ¨tes)
      - [EspÃ©rance](#espÃ©rance)
      - [Variance](#variance)
      - [DiffÃ©rentes lois de probabilitÃ© discrÃ¨tes](#diffÃ©rentes-lois-de-probabilitÃ©-discrÃ¨tes)
  - [Lois de probabilitÃ© continues](#lois-de-probabilitÃ©-continues)
      - [Fonction densitÃ© de probabilitÃ©](#fonction-densitÃ©-de-probabilitÃ©)
      - [EspÃ©rance, Variance](#espÃ©rance-variance)
      - [DiffÃ©rentes lois de probabilitÃ© continues](#diffÃ©rentes-lois-de-probabilitÃ©-continues)
- [ThÃ©orÃ¨mes limites et Approximations](#thÃ©orÃ¨mes-limites-et-approximations)
  - [Lois d'inÃ©galitÃ©s](#lois-dinÃ©galitÃ©s)
  - [ThÃ©orÃ¨me central limite](#thÃ©orÃ¨me-central-limite)
  - [Approximation de Lois](#approximation-de-lois)
    - [B par P](#b-par-p)
    - [B par N](#b-par-n)
- [Formules](#formules)
- [Ã‰chantillonnage, Estimation, Intervalle de confiance](#Ã©chantillonnage-estimation-intervalle-de-confiance)
  - [Distribution d'Ã©chantillonnage de proportion](#distribution-dÃ©chantillonnage-de-proportion)
  - [Estimation ponctuelle](#estimation-ponctuelle)
  - [Estimation par intervalle de confiance](#estimation-par-intervalle-de-confiance)


___
> $$Î©$$ **Espace fondamental :** ensemble des Ã©vÃ©nements Ã©lÃ©mentaires d'une expÃ©rience alÃ©atoire (P(Î©) = totalitÃ© d'un diagramme de Venn = 1).  
> $$(Î©, P(Î©))$$ **Espace Probabilisable :** ensemble des Ã©vÃ©nements de l'univers $$Î©$$.  
> $$(Î©, P(Î©), p)$$ **Espace probabilisÃ© :** probabilitÃ© $$p$$ sur l'univers $$Î©$$.

> **ExpÃ©rience alÃ©atoire :** expÃ©rience dont on ne connait le rÃ©sultat qu'aprÃ¨s l'avoir exÃ©cutÃ©e, mais dont on connaÃ®t toutes les issues.  
> **Ã‰vÃ©nement :** sous-ensemble de l'univers d'une expÃ©rience alÃ©atoire.




___
## SystÃ¨me complet d'Ã©vÃ©nements
Un SCE est formÃ© de toutes les parties de $$Î©$$.
ğŸ“Œ $$âˆªE_{i}=Î©$$  
les parties de $$Î©$$ ne sont prises qu'une fois : $$Eâ‚âˆ©Eâ‚‚=âˆ…$$  
âœğŸ» $$A$$ et $$\bar{A}$$ forment un SCE. C'est pourquoi ğŸ“Œ$$P(B)=P(Aâˆ©B)+P(\bar{A}âˆ©B)$$.







___
## ProbabilitÃ©
Une **probabilitÃ©** se dÃ©finit par l'**application** :  
$$ğŸ“ŒP: 
\begin{cases}
Î© â†’ [0,1] \\
A â†¦ P(A)
\end{cases}$$ 

âœğŸ» Une **application** $$Aâ†’B$$ est une opÃ©ration qui fait correspondre Ã  tout Ã©lÃ©ment x de A **un seul** Ã©lÃ©ment y de B.

> Une probabilitÃ© vÃ©rifie :  
> $$P(A)âŠ‚[0,1]$$  
> $$P(Î©)=1$$  
> ğŸ“Œ$$P(A)âˆªP(B) = P(A)+P(B)-P(A)âˆ©P(B)$$

> **Ã‰vÃ©nements incompatibles :** $$P(A)âˆ©P(B) = âˆ…$$

âœğŸ» PropriÃ©tÃ©s :
- AdditivitÃ© : $$P(Aâˆª\bar{A}) = P(A)+P(\bar{A})$$
- propriÃ©tÃ© de la rÃ©union : $$Aâˆª\bar{A}=Î©$$
- propriÃ©tÃ© de l'intersection : $$Aâˆ©\bar{A} = âˆ…$$

âœğŸ» Soit les Ã©vÃ©nements A, B et C :
- au moins un = $$AâˆªBâˆªC$$
- tous = $$Aâˆ©Bâˆ©C$$
- au plus 2 = tout sauf tous = $$(\overline{Aâˆ©Bâˆ©C})$$

> #### Formule des probabilitÃ©s totales
> Si Bâ‚, Bâ‚‚, Bâ‚ƒ forment une partition de Î©, alors  
> ğŸ“Œ$$P(A)=P(Aâˆ©Bâ‚)+P(Aâˆ©Bâ‚‚)+P(Aâˆ©Bâ‚ƒ)$$

> #### Ã‰quiprobabilitÃ©
> ğŸ“Œ$$P(A)=\frac{card(A)}{card(Î©)}$$  
> avec $$card(E)$$ : taille de l'ensemble E






___
## IndÃ©pendance
Deux Ã©vÃ©nements sont indÃ©pendants si la rÃ©alisation de l'un n'influence pas la rÃ©alisation de l'autre. 
> #### ThÃ©orÃ¨me de l'IndÃ©pendance
> ğŸ“ŒA et B indÃ©pendants ssi $$P(Aâˆ©B)=P(A)P(B)$$
> 
> âœğŸ» Dans ce cas,
> $$P_{A}(B)=P(B)$$  
> $$P_{A}$$ et $$B$$ indÃ©pendants. 






___
## ProbabilitÃ© Conditionelle
> La probabilitÃ© de B dÃ©pendant de A est notÃ©e $$P_{A}(B)$$.  
> ğŸ“Œ$$P_{A}(B)=\frac{P(Aâˆ©B)}{P(A)}$$

> #### Formule des probabilitÃ©s composÃ©es
> ğŸ“Œ$$P(Aâˆ©B)=P(A)P_{A}(B)$$




## Variables alÃ©atoires

### Fonction de rÃ©partition
$$ğŸ“Œx: 
\begin{cases}
â„ â†’ [0;1] \\
t â†¦ F(t)=P(Xâ‰¤t)
\end{cases}$$

ğŸ“Œ$$F(t)=P(Xâ‰¤t)$$

> **PropriÃ©tÃ©s :**
> - F est toujours croissante
> - $$\lim_{tâ†’0}F(t)=0$$.
> - $$\lim_{tâ†’âˆ}F(t)=1$$.

> $$P(aâ‰¤Xâ‰¤b)=P(Xâ‰¤b)-P(Xâ‰¤a)=F(b)-F(a)$$
> P(X>a)=1-P(Xâ‰¤a)=1-F(a)




___
## Variables alÃ©atoires discrÃ¨tes
Une VAD est une fonction qui associe Ã  chaque rÃ©sultat d'une expÃ©rience alÃ©atoire un entier naturel.
Pour toute VAD $$X$$ :
$$ğŸ“Œx: 
\begin{cases}
Î© â†’ â„• \\
Ï‰áµ¢ â†¦ x(Ï‰áµ¢)=xáµ¢
\end{cases}$$ 
___
## Variables alÃ©atoires continues
Une VAC est une fonction qui associe Ã  chaque rÃ©sultat d'une expÃ©rience alÃ©atoire un nombre rÃ©el.
Pour toute VAC $$X$$ :
$$ğŸ“Œx: 
\begin{cases}
Î© â†’ \mathbb{R} \\
Ï‰áµ¢ â†¦ x(Ï‰áµ¢)=xáµ¢
\end{cases}$$ 



___
## Lois de probabilitÃ© DiscrÃ¨tes

> **Loi de probabilitÃ© de X :** ProbabilitÃ© que x prenne chacune des valeurs de X(Î©).
>
|xáµ¢     |0  |1  |2  |
|--     |-- |-- |-- |
|P(X=xáµ¢)|1/8|2/8|5/8|

âœğŸ» Les Ã©vÃ©nements X=xáµ¢ forment un [SystÃ¨me complet d'Ã©vÃ©nements](#systÃ¨me-complet-dÃ©vÃ©nements). C'est pourquoi $$\sum_{i}P(X=xáµ¢)=1$$.

#### EspÃ©rance
L'espÃ©rance reprÃ©sente ce que vaut X en moyenne, aprÃ¨s beaucoup de rÃ©pÃ©titions.

Somme des xáµ¢ pondÃ©rÃ©s par leur probabilitÃ©.  
ğŸ“Œ $$E(X) = âˆ‘ xáµ¢Ã—P(X=xáµ¢)$$  

$$E(X+Y)=E(X)+E(Y)$$  
$$E(kX)=kE(X)$$  
$$E(X+a)=E(X)+a$$

#### Variance 
C'est la moyenne des carrÃ©s des Ã©carts Ã  l'espÃ©rance :   
ğŸ“Œ$$V(X) = âˆ‘ (xáµ¢-E(X))Â² P(X=xáµ¢)$$  
$$V(X) = âˆ‘ (xÂ² P(X=xáµ¢))$$  
$$V(X) = E(XÂ²)-E(X)Â²$$  
$$V(X) = E[(X-E(X))Â²]$$

> **Ã‰cart-type :** ğŸ“Œ$$Ïƒ=\sqrt{V(X)}$$

$$V(X+Y)=V(X)+V(Y)$$  
$$V(kX)=kÂ²V(X)$$  
$$V(X+a)=V(X)$$

#### DiffÃ©rentes lois de probabilitÃ© discrÃ¨tes

|Notation|Nom      |E(X)  |V(X)       |P(X=k)|
|--      |--       |--    |--         |--|
B(p\)     |Bernoulli|$$p$$ |$$p(1-p)$$ |$$kn$$
B(n;p)   |Binomiale|$$np$$|$$np(1-p)$$|$$\binom{n}{k} páµ(1-p)â¿â»áµ$$
P(Î»)     |Poisson  |$$Î»$$ |$$Î»$$      |$$\frac{e^{-Î»}Î»^{k}}{k!}$$

- **Loi de Bernoulli :** pour X ne prenant que 2 valeurs. On rÃ©alise des expÃ©riences de Bernoulli. 
  
|X=xáµ¢|0|1|
|--|--|--|
|P(X=xáµ¢)|1-p|p|

- **Loi binomiale :** Un ensemble de probabilitÃ©s suit la loi binomiale **ssi** il forme un **schÃ©ma de Bernoulli** (EBRII, ExpÃ©riences de Bernoulli RÃ©pÃ©tÃ©es, Identiques, IndÃ©pendantes).  

âœğŸ» Une loi binomiale s'applique par exemple Ã  un tirage avec remise. 

> Coefficient bionomial : ğŸ“Œ$$\binom{n}{k}=\frac{n!}{k!(n-k)!}$$ 
> - $$\binom{n}{k} = \binom{n}{n-k}$$, 
> - $$\binom{n}{k} + \binom{n}{k+1} = \binom{n+1}{k+1}$$ - *Formule de Pascal*,
> - $$\binom{n}{0} = 1$$,    
> - $$\binom{n}{1} = n$$,    
> - $$\binom{n}{n} = 1$$,    
> - $$\binom{0}{0} = 1$$.    

- **Loi de Poisson :** s'applique aux Ã©vÃ©nements rares.






___
## Lois de probabilitÃ© continues

#### Fonction densitÃ© de probabilitÃ©

On suppose que $$F'(t)=f(t)$$.

âœğŸ» F(t) est la densitÃ© de la loi *continue* de X.

$$f(t)â‰¥0$$  
$$\begin{align}
P(aâ‰¤Xâ‰¤b) &= F(b)-F(a) \\
         &= \int_{a}^{b} f(x) \,dx
\end{align}$$  
$$\begin{align}
P(Xâ‰¤b) &= \int_{-âˆ}^{b}f(x) \,dx \\
       &= \lim_{aâ†’+âˆ} \int_{a}^{b}f(x) \,dx \\
       &= F(b)-\lim_{aâ†’-âˆ}F(a)
\end{align}$$  

#### EspÃ©rance, Variance

$$E(X)=\int_{-âˆ}^{+âˆ}xf(x) \,dx$$  
$$V(X)=E(XÂ²)-E(X)Â²$$ avec $$E(XÂ²)=\int_{-âˆ}^{+âˆ}xÂ²f(x) \,dx$$

#### DiffÃ©rentes lois de probabilitÃ© continues

| Notation | Nom | E(X) | V(X) | FDP f(x) | f(x)âŠ‚ | P(câ‰¤Xâ‰¤d) |
| -------- | --- | ---- | ---- | -------- | ----- | -------- |
U(a;b)  | Uniforme      | $$\frac{a+b}{2}$$ | $$\frac{(b-a)Â²}{12}$$ | $$\frac{1}{b-a}$$| $$[a;b]$$  | $$\frac{d-c}{b-a}$$
E(Î»)    | Exponentielle | $$\frac{1}{Î»}$$   | $$\frac{1}{Î»Â²}$$      | $$Î»e^{-Î»x}$$     | $$[a;+âˆ[$$ | $$e^{-Î»c}-e^{-Î»d}$$
N(m;ÏƒÂ²) | Normale       | $$m$$             | $$ÏƒÂ²$$                | $$\frac{e^{-0,5(\frac{x-m}{Ïƒ})Â²}}{Ïƒ\sqrt{2\pi}}$$ | â„ | $$\int_{a}^{b}f(x) \,dx$$
N(0;1)  | Normale CentrÃ©e RÃ©duite | $$0$$ | $$1$$ | $$\frac{e^{xÂ²/2}}{\sqrt{2\pi}}$$ | â„ | $$\int_{a}^{b}f(x) \,dx$$

- **Loi normale centrÃ©e rÃ©duite :**   
Comme la FDP est paire (symÃ©trique) : $$P(Tâ‰¤-u) = P(Tâ‰¥u) = 1-P(Tâ‰¤u)$$





# ThÃ©orÃ¨mes limites et Approximations

## Lois d'inÃ©galitÃ©s
Soit $$X, a âŠ‚ â„^{+}$$
- On ne connait pas la loi de X
- On connaÃ®t E(X)

> ğŸ“Œ InÃ©galitÃ© de Markov :      
> $$P(Xâ‰¥a) = \frac{E(X)}{a}$$

> ğŸ“Œ InÃ©galitÃ© de BienaymÃ© - Tchebychev :  
> $$P(|X-E(X)|â‰¥a) â‰¤ \frac{V(X)}{aÂ²}$$

## ThÃ©orÃ¨me central limite
Soit n VA ~ L de mÃªme espÃ©rance.
> Soit $$Y = X_1+...+X_n$$
> Y ~ approx. $$N(m, Ïƒ)$$ avec
> - $$E(Y) = nÃ—m$$
> - $$Ïƒ(Y) = ÏƒÃ—\sqrt{n}$$

> Soit $$\bar{Y}=\frac{X_1+...+X_n}{n}$$
> Y ~ approx. $$N(m, Ïƒ)$$ avec
> - $$E(\bar{X}) = m$$
> - $$Ïƒ(\bar{X}) = \frac{Ïƒ}{\sqrt{n}}$$

âœï¸ Il n'y a pas d'approximation quand $$X_i \sim N(M, Ïƒ)$$ d'aprÃ¨s la stabilitÃ© de $$N$$.

## Approximation de Lois
### B par P
La table de $$B$$ n'existe pas pour $$nâ‰¥50$$, mais on peu approcher $$B(n, p)$$ par $$P(Î»)$$ ssi :
- E et V de $$B(n, p)$$ et $$P(Î»)$$ doivent Ãªtre Ã©gales.
- $$Î»=nÃ—p$$
- $$Î»â‰¤16$$

ğŸ“Œ $$\underset{B(n,p)}{P(X=k)} = \underset{P(nÃ—p)}{P(X=k)}$$  
ğŸ“Œ $$\underset{B(n,p)}{P(aâ‰¤Xâ‰¤b)} = \underset{P(nÃ—p)}{P(aâ‰¤Xâ‰¤b)}$$

âœï¸ L'approximation est bonne dÃ¨s que :
- P \< 0,1 
- N â‰¥ 30
- nÃ—p \< 15

### B par N
On peut dÃ©composer $$X \sim B(n, p)$$ en $$X_i$$ qui suivent la mÃªme loi avec :
- $$E(X_i)=p$$
- $$V(X_i)=p(1-p)$$

D'aprÃ¨s le thÃ©orÃ¨me central limite, $$X \sim N(nÃ—p, Ïƒ)$$

ğŸ“Œ $$P(Î») â‰ˆ N(Î», \sqrt{Î»})$$

# Formules

IncompatibilitÃ© | $$Aâˆ©B=âˆ…$$  

ProbabilitÃ© | $$P: \begin{cases}Î© â†’ [0,1] \\A â†¦ P(A)\end{cases}$$

ProbabilitÃ©s totales | $$P(A)=P(Aâˆ©Bâ‚)+P(Aâˆ©Bâ‚‚)+P(Aâˆ©Bâ‚ƒ)$$  

Ã‰quiprobabilitÃ© | $$P(A)=\frac{card(A)}{card(Î©)}$$  

Union | $$P(Aâˆ©B)=P(A)P(B)-P(AâˆªB)$$  

IndÃ©pendance | $$P(Aâˆ©B)=P(A)P(B)$$  

ProbabilitÃ©s composÃ©es | $$P(Aâˆ©B)=P(A)P_{A}(B)$$  

Variable AlÃ©atoire discrÃ¨te | $$x: \begin{cases}Î© â†’ â„ \\Ï‰áµ¢ â†¦ x(Ï‰áµ¢)=xáµ¢\end{cases}$$   

EspÃ©rance | $$Î£(xáµ¢) P(X=xáµ¢)$$  

Variance | $$E[(X-E(X))Â²]$$  



# Ã‰chantillonnage, Estimation, Intervalle de confiance

Soit une **population** sur laquelle on a une Variable AlÃ©atoire :
- de moyenne $$m$$
- d'Ã©cart-type $$Ïƒ$$
- de probabilitÃ© $$p$$

On suppose :
- La population infinie
- Les tirages sont avec remise

| ParamÃ¨tre  | Population | Ã‰chantillon |
| ---------- | ---------- | ----------- |
| moyenne    | $$m$$      | $$\bar{x}$$ |
| Ã©cart-type | $$Ïƒ$$      | $$s$$       |
| proportion | $$p$$      | $$f$$       |
| taille     | $$Nâ†’âˆ$$    | $$nâ‰¥30$$    |

## Distribution d'Ã©chantillonnage de proportion

$$f_1$$ est la proportion d'individus possÃ©dant le caractÃ¨re $$A$$ dans l'Ã©chantillon $$i$$.

$${f_1, f_2, ...}$$ est la distribution d'Ã©chantillonnage de proportion.

> Y : VA qui associe le nombre d'individus possÃ©dant le caractÃ¨re A Ã  un Ã©chantillon donnÃ©.
> - loi de Y : $$Y âˆ¼ B(n,p)$$

> F : VA associant $$f_i$$ Ã  chaque $$i$$.
> - lien avec Y : $$F=\frac{Y}{n}$$
> - Loi de F : on approche $$Y âˆ¼ B(n,p)$$ par $$F âˆ¼ N(p, \sqrt{p(1-p)/n}$$
> - EspÃ©rance de F : $$E(F) = E(Y/n) = E(Y)/n = p$$
> - Variance de F : $$V(F) = V(Y/n) = V(Y)/nÂ² = \frac{p(1-p)}{n}$$

$${\bar{X_1}, \bar{X_2}, ...}$$ est la distribution d'Ã©chantillonnage des moyennes.

> $$\bar{X}$$ est une VA associant $$\bar{X_i}$$ Ã  chaque Ã©chantillon $$i$$. $$\bar{X} = \frac{\sum_1^n x_i}{n}$$
> - Loi de $$\bar{X}$$ : d'aprÃ¨s le **ThÃ©orÃ¨me central limite**, $$\bar{X} âˆ¼ N(m, Ïƒ/\sqrt{n}$$

> $$X_i$$ est une VA qui reprÃ©sente la valeur du $$i^Ã¨me$$ tirage.
> - EspÃ©rance : $$E(X_i) = Î£E(X)/n = m$$
> - Variance : $$V(X_i) = Î£x_i/nÂ² = ÏƒÂ²$$

## Estimation ponctuelle

Estimer la population (m, Ïƒ, p) Ã  partir d'un Ã©chantillon (\bar{x}, s, f).

> Estimation ponctuelle de la moyenne : $$\hat{m} = \bar{x}$$

> Estimation ponctuelle de l'Ã©cart-type : $$\hat{Ïƒ} = sÃ—\sqrt{\frac{n}{n-1}}>s$$
> avec $$\frac{n}{n-1}$$ coefficient de biais.

> Estimation ponctuelle de la proportion : $$\hat{p} = f$$

## Estimation par intervalle de confiance

On connaÃ®t $$\bar{x}$$ d'un Ã©chantillon.

> **Intervalle de confiance :** $$[\bar{x}-a, \bar{x}+a]$$ avec $$a âŠ‚ \R^+$$.
> Intervalle contenant $$m$$ avec un degrÃ© de confiance de 95%.
> $$I_{0,95} = [\bar{x}-\frac{1,96Ïƒ}{\sqrt{n}}, \bar{x}+\frac{1,96Ïƒ}{\sqrt{n}}]$$

âœï¸ Si on ne connaÃ®t pas Ïƒ on peut utiliser $$\hat{Ïƒ} = sÃ—\sqrt{\frac{n}{n-1}}>s$$